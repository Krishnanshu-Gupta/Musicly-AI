{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import math, json, os\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m123,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,204</span> (625.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,204\u001b[0m (625.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,882</span> (624.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m159,882\u001b[0m (624.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('model_cnn2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(file_path, fs=22050, n_mfcc=11, n_fft=2048, hop_length=512, segment_duration=30):\n",
    "    \"\"\"\n",
    "    Predict the genre of an audio file, ensuring the correct input shape for the model.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        fs (int): Sampling rate for audio.\n",
    "        n_mfcc (int): Number of MFCC coefficients (features).\n",
    "        n_fft (int): FFT window size.\n",
    "        hop_length (int): Number of samples between successive frames.\n",
    "        segment_duration (int): Duration of each segment in seconds.\n",
    "\n",
    "    Returns:\n",
    "        predicted_genre (str): Predicted genre of the audio.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio, _ = librosa.load(file_path, sr=fs)\n",
    "\n",
    "    # Calculate segment length in samples\n",
    "    segment_length = fs * segment_duration\n",
    "\n",
    "    # Handle short audio: Pad to 30 seconds\n",
    "    if len(audio) < segment_length:\n",
    "        audio = np.pad(audio, (0, segment_length - len(audio)), mode='constant')\n",
    "\n",
    "    # Handle long audio: Split into segments\n",
    "    num_segments = len(audio) // segment_length\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start = i * segment_length\n",
    "        end = start + segment_length\n",
    "        segment = audio[start:end]\n",
    "\n",
    "        # Extract MFCCs for the segment\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=segment,\n",
    "            sr=fs,\n",
    "            n_mfcc=n_mfcc,  # Match the expected number of features\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "\n",
    "        # Ensure we have exactly 128 time steps\n",
    "        if mfcc.shape[1] < 128:  # Pad if shorter\n",
    "            mfcc = np.pad(mfcc, ((0, 0), (0, 128 - mfcc.shape[1])), mode='constant')\n",
    "        else:  # Truncate if longer\n",
    "            mfcc = mfcc[:, :128]\n",
    "\n",
    "        # Transpose to match the model's input shape (time_steps, features)\n",
    "        mfcc = mfcc.T  # Now shape is (128, 11)\n",
    "\n",
    "        # Add batch and channel dimensions\n",
    "        # Final shape should be (batch_size, time_steps, features, channels)\n",
    "        mfcc = mfcc[np.newaxis, ..., np.newaxis]  # Reshape to (1, 128, 11, 1)\n",
    "\n",
    "        # Predict the genre for this segment\n",
    "        pred_probs = model.predict(mfcc, verbose=0)\n",
    "        pred_class = np.argmax(pred_probs, axis=1)\n",
    "        predictions.append(pred_class[0])\n",
    "\n",
    "    # Aggregate predictions across all segments\n",
    "    from collections import Counter\n",
    "    most_common_genre = Counter(predictions).most_common(1)[0][0]\n",
    "\n",
    "    # Map to genre name\n",
    "    genre_map = {0: 'Blues', 1: 'Classical', 2: 'Country', 3: 'Disco', 4: 'Hip Hop',\n",
    "                 5: 'Jazz', 6: 'Metal', 7: 'Pop', 8: 'Reggae', 9: 'Rock'}\n",
    "    predicted_genre = genre_map[most_common_genre]\n",
    "\n",
    "    return predicted_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(file_path, fs=22050, n_mfcc=13, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Predict the genre of an audio file by splitting it into 3-second segments.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        fs (int): Sampling rate for audio.\n",
    "        n_mfcc (int): Number of MFCC coefficients (features).\n",
    "        n_fft (int): FFT window size.\n",
    "        hop_length (int): Number of samples between successive frames.\n",
    "\n",
    "    Returns:\n",
    "        predicted_genre (str): Predicted genre of the audio.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio, _ = librosa.load(file_path, sr=fs)\n",
    "\n",
    "    # Get total duration of the audio in seconds\n",
    "    total_duration = librosa.get_duration(y=audio, sr=fs)\n",
    "    print(f\"Duration of audio: {total_duration:.2f} seconds\")\n",
    "\n",
    "    # Calculate the number of 3-second segments\n",
    "    segment_duration = 3  # seconds\n",
    "    num_segments = int(total_duration // segment_duration)\n",
    "    print(f\"Number of 3-second segments: {num_segments}\")\n",
    "\n",
    "    # Calculate segment length in samples\n",
    "    segment_length = fs * segment_duration  # Samples per segment\n",
    "    predictions = []\n",
    "\n",
    "    # Process each 3-second segment\n",
    "    for segment in range(num_segments):\n",
    "        start = segment * segment_length\n",
    "        end = start + segment_length\n",
    "        segment_audio = audio[start:end]\n",
    "\n",
    "        # Extract MFCCs\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=segment_audio,\n",
    "            sr=fs,\n",
    "            n_mfcc=n_mfcc,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "\n",
    "        # Ensure MFCC has the expected shape\n",
    "        if mfcc.shape[1] < 128:  # Pad if shorter\n",
    "            mfcc = np.pad(mfcc, ((0, 0), (0, 128 - mfcc.shape[1])), mode='constant')\n",
    "        else:  # Truncate if longer\n",
    "            mfcc = mfcc[:, :128]\n",
    "\n",
    "        # Transpose MFCC to match the model's input shape (time_steps, features)\n",
    "        mfcc = mfcc.T  # Shape: (128, n_mfcc)\n",
    "\n",
    "        # Add batch and channel dimensions\n",
    "        mfcc = mfcc[np.newaxis, ..., np.newaxis]  # Shape: (1, 128, n_mfcc, 1)\n",
    "\n",
    "        # Predict genre for the segment\n",
    "        pred_probs = model.predict(mfcc, verbose=0)\n",
    "        pred_class = np.argmax(pred_probs, axis=1)\n",
    "        predictions.append(pred_class[0])\n",
    "\n",
    "    # Aggregate predictions across all 3-second segments\n",
    "    from collections import Counter\n",
    "    most_common_genre = Counter(predictions).most_common(1)[0][0]\n",
    "\n",
    "    # Map to genre name\n",
    "    genre_map = {0: 'Blues', 1: 'Classical', 2: 'Country', 3: 'Disco', 4: 'Hip Hop',\n",
    "                 5: 'Jazz', 6: 'Metal', 7: 'Pop', 8: 'Reggae', 9: 'Rock'}\n",
    "    predicted_genre = genre_map[most_common_genre]\n",
    "\n",
    "    return predicted_genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_for_song(file_path, fs=22050, duration=30, n_fft=2048, hop_length=512, n_mfcc=13, num_segments=10):\n",
    "    \"\"\"\n",
    "    Extract MFCCs from a single audio file.\n",
    "    Splits the audio into smaller segments for better analysis and training data.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        fs (int): Sampling rate for the audio.\n",
    "        duration (int): Duration of the audio in seconds (default is 30).\n",
    "        n_fft (int): FFT window size.\n",
    "        hop_length (int): Number of samples between successive frames.\n",
    "        n_mfcc (int): Number of MFCC coefficients.\n",
    "        num_segments (int): Number of segments to split the audio into.\n",
    "\n",
    "    Returns:\n",
    "        mfcc_data (list): List of MFCCs for each segment of the audio file.\n",
    "    \"\"\"\n",
    "    samples_per_track = fs * duration\n",
    "    samples_per_segment = int(samples_per_track / num_segments)\n",
    "    mfccs_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    print(\"Starting MFCC extraction for file...\")\n",
    "    mfcc_data = []\n",
    "\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, _ = librosa.load(file_path, sr=fs)\n",
    "\n",
    "        for segment in range(num_segments):\n",
    "            start = segment * samples_per_segment\n",
    "            end = start + samples_per_segment\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=audio[start:end], sr=fs, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length\n",
    "            ).T\n",
    "\n",
    "            # Validate segment shape\n",
    "            if len(mfcc) == mfccs_per_segment:\n",
    "                mfcc_data.append(mfcc.tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    #print(f\"Finished extracting MFCCs for: {os.path.basename(file_path)}\")\n",
    "    return mfcc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/genres_original/blues/blues.00002.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m mfccs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_mfcc_for_song\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m22050\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_segments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mfcc \u001b[38;5;129;01min\u001b[39;00m mfccs:\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mextract_mfcc_for_song\u001b[0;34m(file_path, fs, duration, n_fft, hop_length, n_mfcc, num_segments)\u001b[0m\n\u001b[1;32m     18\u001b[0m samples_per_track \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;241m*\u001b[39m duration\n\u001b[1;32m     19\u001b[0m samples_per_segment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(samples_per_track \u001b[38;5;241m/\u001b[39m num_segments)\n\u001b[0;32m---> 20\u001b[0m mfccs_per_segment \u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241m.\u001b[39mceil(samples_per_segment \u001b[38;5;241m/\u001b[39m hop_length)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting MFCC extraction for file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m mfcc_data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "path1 = \"./data/genres_original/blues/blues.00002.wav\"\n",
    "mfccs = extract_mfcc_for_song(\n",
    "    file_path=path1,\n",
    "    fs=22050,\n",
    "    duration=30,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    n_mfcc=13,\n",
    "    num_segments=10\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "for mfcc in mfccs:\n",
    "    mfcc_array = np.array(mfcc)  # Convert list to numpy array\n",
    "    mfcc_array = mfcc_array[np.newaxis, ..., np.newaxis]  # Add batch and channel dimensions\n",
    "\n",
    "    # Predict the genre for this MFCC\n",
    "    pred_probs = model.predict(mfcc_array, verbose=0)\n",
    "    pred_class = np.argmax(pred_probs, axis=1)\n",
    "    predictions.append(pred_class[0])\n",
    "\n",
    "# Aggregate predictions across all segments\n",
    "from collections import Counter\n",
    "most_common_genre = Counter(predictions).most_common(1)[0][0]\n",
    "\n",
    "# Map prediction to genre name\n",
    "genre_map = {0: 'Blues', 1: 'Classical', 2: 'Country', 3: 'Disco', 4: 'Hip Hop',\n",
    "             5: 'Jazz', 6: 'Metal', 7: 'Pop', 8: 'Reggae', 9: 'Rock'}\n",
    "predicted_genre = genre_map[most_common_genre]\n",
    "\n",
    "# Print the result\n",
    "print(f\"Predicted Genre: {predicted_genre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Metal\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Metal\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Disco\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Disco\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Disco\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Hip Hop\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Disco\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Disco\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Rock\n",
      "Duration of audio: 30.01 seconds\n",
      "Number of 3-second segments: 10\n",
      "Predicted Genre (Short Audio): Disco\n"
     ]
    }
   ],
   "source": [
    "path1 = wav_files[\"blues1\"]  # Example: Blues song 1\n",
    "path1 = \"./data/genres_original/blues/blues.00001.wav\"\n",
    "path2 = \"./data/genres_original/blues/blues.00002.wav\"\n",
    "path3 = \"./data/genres_original/blues/blues.00003.wav\"\n",
    "path4 = \"./data/genres_original/blues/blues.00004.wav\"\n",
    "path5 = \"./data/genres_original/blues/blues.00005.wav\"\n",
    "path6 = \"./data/genres_original/blues/blues.00006.wav\"\n",
    "path7 = \"./data/genres_original/blues/blues.00007.wav\"\n",
    "path8 = \"./data/genres_original/blues/blues.00008.wav\"\n",
    "path9 = \"./data/genres_original/blues/blues.00009.wav\"\n",
    "path10 = \"./data/genres_original/blues/blues.00010.wav\"\n",
    "\n",
    "mfccs = extract_mfcc_for_song(\n",
    "    file_path=path1,\n",
    "    fs=22050,\n",
    "    duration=30,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    n_mfcc=13,\n",
    "    num_segments=10\n",
    ")\n",
    "\n",
    "genre1 = predict_audio(path1)\n",
    "print(f\"Predicted Genre (Short Audio): {genre1}\")\n",
    "genre2 = predict_audio(path2)\n",
    "print(f\"Predicted Genre (Short Audio): {genre2}\")\n",
    "genre3 = predict_audio(path3)\n",
    "print(f\"Predicted Genre (Short Audio): {genre3}\")\n",
    "genre4 = predict_audio(path4)\n",
    "print(f\"Predicted Genre (Short Audio): {genre4}\")\n",
    "genre5 = predict_audio(path5)\n",
    "print(f\"Predicted Genre (Short Audio): {genre5}\")\n",
    "genre6 = predict_audio(path6)\n",
    "print(f\"Predicted Genre (Short Audio): {genre6}\")\n",
    "genre7 = predict_audio(path7)\n",
    "print(f\"Predicted Genre (Short Audio): {genre7}\")\n",
    "genre8 = predict_audio(path8)\n",
    "print(f\"Predicted Genre (Short Audio): {genre8}\")\n",
    "genre9 = predict_audio(path9)\n",
    "print(f\"Predicted Genre (Short Audio): {genre9}\")\n",
    "genre10 = predict_audio(path10)\n",
    "print(f\"Predicted Genre (Short Audio): {genre10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_to_wav(path, target_path):\n",
    "    \"\"\"\n",
    "    Convert an audio file to WAV format using PyDub.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_file(path)\n",
    "    audio.export(target_path, format=\"wav\")\n",
    "    print(f\"Converted {path} to {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "blues1 = \"./tests/blues_crossroads.mp3\"\n",
    "blues2 = \"./tests/blues_thrillisgone.mp3\"\n",
    "\n",
    "classical1 = \"./tests/classical_beethoven9.mp3\"\n",
    "classical2 = \"./tests/classical_mozart.mp3\"\n",
    "\n",
    "country1 = \"./tests/country_takemehome.mp3\"\n",
    "country2 = \"./tests/country_jolene.mp3\"\n",
    "\n",
    "disco1 = \"./tests/disco_stayingalive.mp3\"\n",
    "disco2 = \"./tests/disco_ymca.mp3\"\n",
    "\n",
    "hiphop1 = \"./tests/hiphop_sickomode.mp3\"\n",
    "hiphop2 = \"./tests/hiphop_luciddreams.mp3\"\n",
    "\n",
    "jazz1 = \"./tests/jazz_flymetothemoon.mp3\"\n",
    "jazz2 = \"./tests/jazz_whatawonderfulworld.mp3\"\n",
    "\n",
    "metal1 = \"./tests/metal_masterofpuppets.mp3\"\n",
    "metal2 = \"./tests/metal_ironman.mp3\"\n",
    "\n",
    "pop1 = \"./tests/pop_shapeofyou.mp3\"\n",
    "pop2 = \"./tests/pop_baby.mp3\"\n",
    "\n",
    "reggae1 = \"./tests/reggae_nowomannocry.mp3\"\n",
    "reggae2 = \"./tests/reggae_badboys.mp3\"\n",
    "\n",
    "rock1 = \"./tests/rock_bohemianrhapsody.mp3\"\n",
    "rock2 = \"./tests/rock_stairwaytoheaven.mp3\"\n",
    "\n",
    "# wav file paths\n",
    "wav_files = {\n",
    "    \"blues1\": \"./tests/blues_crossroads.wav\",\n",
    "    \"blues2\": \"./tests/blues_thrillisgone.wav\",\n",
    "    \"classical1\": \"./tests/classical_beethoven9.wav\",\n",
    "    \"classical2\": \"./tests/classical_mozart.wav\",\n",
    "    \"country1\": \"./tests/country_takemehome.wav\",\n",
    "    \"country2\": \"./tests/country_jolene.wav\",\n",
    "    \"disco1\": \"./tests/disco_stayingalive.wav\",\n",
    "    \"disco2\": \"./tests/disco_ymca.wav\",\n",
    "    \"hiphop1\": \"./tests/hiphop_sickomode.wav\",\n",
    "    \"hiphop2\": \"./tests/hiphop_luciddreams.wav\",\n",
    "    \"jazz1\": \"./tests/jazz_flymetothemoon.wav\",\n",
    "    \"jazz2\": \"./tests/jazz_whatawonderfulworld.wav\",\n",
    "    \"metal1\": \"./tests/metal_masterofpuppets.wav\",\n",
    "    \"metal2\": \"./tests/metal_ironman.wav\",\n",
    "    \"pop1\": \"./tests/pop_shapeofyou.wav\",\n",
    "    \"pop2\": \"./tests/pop_baby.wav\",\n",
    "    \"reggae1\": \"./tests/reggae_nowomannocry.wav\",\n",
    "    \"reggae2\": \"./tests/reggae_badboys.wav\",\n",
    "    \"rock1\": \"./tests/rock_bohemianrhapsody.wav\",\n",
    "    \"rock2\": \"./tests/rock_stairwaytoheaven.wav\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ./tests/blues_crossroads.mp3 to ./tests/blues_crossroads.wav\n",
      "Converted ./tests/blues_thrillisgone.mp3 to ./tests/blues_thrillisgone.wav\n",
      "Converted ./tests/classical_beethoven9.mp3 to ./tests/classical_beethoven9.wav\n",
      "Converted ./tests/classical_mozart.mp3 to ./tests/classical_mozart.wav\n",
      "Converted ./tests/country_takemehome.mp3 to ./tests/country_takemehome.wav\n",
      "Converted ./tests/country_jolene.mp3 to ./tests/country_jolene.wav\n",
      "Converted ./tests/disco_stayingalive.mp3 to ./tests/disco_stayingalive.wav\n",
      "Converted ./tests/disco_ymca.mp3 to ./tests/disco_ymca.wav\n",
      "Converted ./tests/hiphop_sickomode.mp3 to ./tests/hiphop_sickomode.wav\n",
      "Converted ./tests/hiphop_luciddreams.mp3 to ./tests/hiphop_luciddreams.wav\n",
      "Converted ./tests/jazz_flymetothemoon.mp3 to ./tests/jazz_flymetothemoon.wav\n",
      "Converted ./tests/jazz_whatawonderfulworld.mp3 to ./tests/jazz_whatawonderfulworld.wav\n",
      "Converted ./tests/metal_masterofpuppets.mp3 to ./tests/metal_masterofpuppets.wav\n",
      "Converted ./tests/metal_ironman.mp3 to ./tests/metal_ironman.wav\n",
      "Converted ./tests/pop_shapeofyou.mp3 to ./tests/pop_shapeofyou.wav\n",
      "Converted ./tests/pop_baby.mp3 to ./tests/pop_baby.wav\n",
      "Converted ./tests/reggae_nowomannocry.mp3 to ./tests/reggae_nowomannocry.wav\n",
      "Converted ./tests/reggae_badboys.mp3 to ./tests/reggae_badboys.wav\n",
      "Converted ./tests/rock_bohemianrhapsody.mp3 to ./tests/rock_bohemianrhapsody.wav\n",
      "Converted ./tests/rock_stairwaytoheaven.mp3 to ./tests/rock_stairwaytoheaven.wav\n"
     ]
    }
   ],
   "source": [
    "mp3_files = [blues1, blues2, classical1, classical2, country1, country2,\n",
    "             disco1, disco2, hiphop1, hiphop2, jazz1, jazz2,\n",
    "             metal1, metal2, pop1, pop2, reggae1, reggae2, rock1, rock2]\n",
    "\n",
    "for key, wav_path in wav_files.items():\n",
    "    convert_to_wav(eval(key), wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre (Short Audio): Rock\n",
      "Predicted Genre (Long Audio): Reggae\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "path1 = wav_files[\"blues1\"]  # Example: Blues song 1\n",
    "genre1 = predict_audio(path1)\n",
    "print(f\"Predicted Genre (Short Audio): {genre1}\")\n",
    "\n",
    "path2 = wav_files[\"rock2\"]  # Example: Rock song 2\n",
    "genre2 = predict_audio(path2)\n",
    "print(f\"Predicted Genre (Long Audio): {genre2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre (New Audio): Country\n"
     ]
    }
   ],
   "source": [
    "new_audio_path = './data/genres_original/reggae/reggae.00000.wav'\n",
    "genre = predict_audio(new_audio_path)\n",
    "print(f\"Predicted Genre (New Audio): {genre}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "487",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
